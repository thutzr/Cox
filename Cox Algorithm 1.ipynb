{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里主要用到了`pycox`中的CoxPH模型(DeepSurv)，它是解决连续时间参数情形的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pycox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "from pycox.datasets import metabric\n",
    "from pycox.evaluation import EvalSurv\n",
    "from pycox.models import CoxPH\n",
    "np.random.seed(1234)\n",
    "_ = torch.manual_seed(123)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 计算weight的函数，输入traning set, calibration set以及一个用来估计P(T=1|X=x)的分类模型\n",
    "def compute_weight(classification_model,Z_tr,Z_ca):\n",
    "    '''\n",
    "    classification_model: 'RF','LR','XGBoost'\n",
    "    '''\n",
    "    Z_ca_1 = Z_ca[Z_ca['event']==1]\n",
    "    X_tr = x_mapper.fit_transform(Z_tr).astype('float32')\n",
    "    X_ca = x_mapper.transform(Z_ca_1).astype('float32')\n",
    "    C_tr = Z_tr.iloc[:,-1] # training set的event,用于之后训练分类模型\n",
    "    # 根据输入选择分类模型\n",
    "    if classification_model == 'RF':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        clf = RandomForestClassifier(max_depth=2,random_state=0)\n",
    "    elif classification_model == 'LR':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        clf = LogisticRegression(random_state=0)\n",
    "    elif classification_model == 'XGBoost':\n",
    "        import xgboost as xgb\n",
    "        clf = xgb.XGBClassifier()\n",
    "    clf.fit(X_tr,C_tr) # 训练分类模型\n",
    "    p_predict = clf.predict_proba(X_ca)[:,1] # 预测p_hat\n",
    "    # TBD\n",
    "    W = np.divide(p_predict,(1-p_predict)) # 估计w_hat\n",
    "    return (W,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 计算normalized weight,输入计算的weight，test point，训练过的分类模型\n",
    "def compute_normalized_weight(W,x,trained_classification_model):\n",
    "    '''\n",
    "    x: test point\n",
    "    '''\n",
    "    p_predict = trained_classification_model.predict_proba(x)[0,1] # 预测test point对应的T=1的概率\n",
    "    w_predict = p_predict/(1-p_predict) # 估计p_hat\n",
    "    normalize_term = np.sum(W)+w_predict \n",
    "    p_hat = [i/normalize_term for i in W] # 计算所有病人的p_hat\n",
    "    p_inf = w_predict/normalize_term # 计算无穷点的weight\n",
    "    \n",
    "    return np.array(p_hat+[p_inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generate_distribution(V,p_hat,p_inf):\n",
    "    V += [np.inf]\n",
    "    V = np.array(V)\n",
    "    p_hat = np.array(p_hat+[p_inf])\n",
    "    return (V,p_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 计算对应的置信区间，输入nonconformal score, normalized weight p_hat, p_inf,以及指定的percentile\n",
    "def compute_quantile(V,p_hat,Z_tr,percentile,x,t,model,bh,non_zero_idx):\n",
    "    '''\n",
    "    t: 指定的值\n",
    "    V: 这是calibration set对应的V\n",
    "    '''\n",
    "    ch = model.predict_cumulative_hazards(x)\n",
    "    exp_g_x = ch.loc[non_zero_idx]/bh\n",
    "    exp_g_x_r = compute_nonconformal_score_single(model,Z_tr,x,t,x_mapper,bh,non_zero_idx)\n",
    "    if exp_g_x_r is None:\n",
    "        return -1 # 注意这里需要修改\n",
    "    V_x = np.log(exp_g_x)-np.log(np.sum(exp_g_x_r))\n",
    "    p_hat_leave = p_hat[V<=V_x[0]]\n",
    "    return sum(p_hat_leave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def weighted_conformal_prediction(V,W,x,t_h,Z_tr,model,trained_clf,percentile,bh,non_zero_idx,epsilon=0.01):\n",
    "    p_hat = compute_normalized_weight(W,x,trained_clf)\n",
    "    quantile = 0\n",
    "    t_l = 0\n",
    "    while (abs(quantile-percentile)>epsilon) or (quantile<percentile):\n",
    "        t = (t_l+t_h)/2\n",
    "        quantile = compute_quantile(V,p_hat,Z_tr,percentile,x,t,model,bh,non_zero_idx)\n",
    "        if (quantile > percentile) and (abs(quantile-percentile)>epsilon):\n",
    "            t_h = t\n",
    "            t = (t_h+t_l)/2\n",
    "        else:\n",
    "            t_l = t\n",
    "            t = (t_h+t_l)/2\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 划分数据，输入原始数据，选择划分的比例，输出训练集验证集和calibration set\n",
    "def split_data(df,train_frac=0.6,calibration_frac=0.2):\n",
    "    tr_df = df.sample(frac=train_frac)\n",
    "    df = df.drop(tr_df.index)\n",
    "    ca_df = df.sample(frac=calibration_frac/(1-train_frac))\n",
    "    df = df.drop(ca_df.index)\n",
    "    val_df = df\n",
    "    return (tr_df,val_df,ca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据并划分\n",
    "df_train = metabric.read_df()\n",
    "Z_tr,Z_val,Z_ca = split_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.603834</td>\n",
       "      <td>7.811392</td>\n",
       "      <td>10.797988</td>\n",
       "      <td>5.967607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.840000</td>\n",
       "      <td>99.333336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.284882</td>\n",
       "      <td>9.581043</td>\n",
       "      <td>10.204620</td>\n",
       "      <td>5.664970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.940002</td>\n",
       "      <td>95.733330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.920251</td>\n",
       "      <td>6.776564</td>\n",
       "      <td>12.431715</td>\n",
       "      <td>5.873857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.439999</td>\n",
       "      <td>140.233337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.654017</td>\n",
       "      <td>5.341846</td>\n",
       "      <td>8.646379</td>\n",
       "      <td>5.655888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.910004</td>\n",
       "      <td>239.300003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.456747</td>\n",
       "      <td>5.339741</td>\n",
       "      <td>10.555724</td>\n",
       "      <td>6.008429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.849998</td>\n",
       "      <td>56.933334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>5.946987</td>\n",
       "      <td>5.370492</td>\n",
       "      <td>12.345780</td>\n",
       "      <td>5.741395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.839996</td>\n",
       "      <td>87.233330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>5.339228</td>\n",
       "      <td>5.408853</td>\n",
       "      <td>12.176101</td>\n",
       "      <td>5.693043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.090000</td>\n",
       "      <td>157.533340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>5.901610</td>\n",
       "      <td>5.272237</td>\n",
       "      <td>14.200950</td>\n",
       "      <td>6.139390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.770000</td>\n",
       "      <td>37.866665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>6.818109</td>\n",
       "      <td>5.372744</td>\n",
       "      <td>11.652624</td>\n",
       "      <td>6.077852</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.889999</td>\n",
       "      <td>198.433334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>5.725708</td>\n",
       "      <td>5.449718</td>\n",
       "      <td>9.680736</td>\n",
       "      <td>6.595955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.630001</td>\n",
       "      <td>140.766663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1904 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1         x2        x3   x4   x5   x6   x7         x8  \\\n",
       "0     5.603834  7.811392  10.797988  5.967607  1.0  1.0  0.0  1.0  56.840000   \n",
       "1     5.284882  9.581043  10.204620  5.664970  1.0  0.0  0.0  1.0  85.940002   \n",
       "2     5.920251  6.776564  12.431715  5.873857  0.0  1.0  0.0  1.0  48.439999   \n",
       "3     6.654017  5.341846   8.646379  5.655888  0.0  0.0  0.0  0.0  66.910004   \n",
       "4     5.456747  5.339741  10.555724  6.008429  1.0  0.0  0.0  1.0  67.849998   \n",
       "...        ...       ...        ...       ...  ...  ...  ...  ...        ...   \n",
       "1899  5.946987  5.370492  12.345780  5.741395  1.0  1.0  0.0  1.0  76.839996   \n",
       "1900  5.339228  5.408853  12.176101  5.693043  1.0  1.0  0.0  1.0  63.090000   \n",
       "1901  5.901610  5.272237  14.200950  6.139390  0.0  0.0  0.0  1.0  57.770000   \n",
       "1902  6.818109  5.372744  11.652624  6.077852  1.0  0.0  0.0  1.0  58.889999   \n",
       "1903  5.725708  5.449718   9.680736  6.595955  1.0  1.0  0.0  0.0  60.630001   \n",
       "\n",
       "        duration  event  \n",
       "0      99.333336      0  \n",
       "1      95.733330      1  \n",
       "2     140.233337      0  \n",
       "3     239.300003      0  \n",
       "4      56.933334      1  \n",
       "...          ...    ...  \n",
       "1899   87.233330      1  \n",
       "1900  157.533340      0  \n",
       "1901   37.866665      1  \n",
       "1902  198.433334      0  \n",
       "1903  140.766663      0  \n",
       "\n",
       "[1904 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 将数据标准化\n",
    "cols_standardize = ['x0', 'x1', 'x2', 'x3', 'x8']\n",
    "cols_leave = ['x4', 'x5', 'x6', 'x7']\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize + leave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_mapper.fit_transform(Z_tr).astype('float32')\n",
    "x_val = x_mapper.transform(Z_val).astype('float32')\n",
    "x_ca = x_mapper.transform(Z_ca).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "y_train = get_target(Z_tr)\n",
    "y_val = get_target(Z_val)\n",
    "durations_test, events_test = get_target(Z_ca)\n",
    "val = x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 搭建神经网络\n",
    "in_features = x_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "batch_size=256\n",
    "dropout = 0.1\n",
    "output_bias = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(32),\n",
    "    torch.nn.Dropout(0.1),\n",
    "    \n",
    "    torch.nn.Linear(32, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(32),\n",
    "    torch.nn.Dropout(0.1),\n",
    "    \n",
    "    torch.nn.Linear(32, out_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoxPH模型，使用Adam优化器\n",
    "model = CoxPH(net, torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 512\n",
    "callbacks = [tt.callbacks.EarlyStopping()]\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 4.9349,\tval_loss: 4.4688\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 4.7703,\tval_loss: 4.4529\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 4.6512,\tval_loss: 4.4320\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 4.6480,\tval_loss: 4.4125\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 4.6010,\tval_loss: 4.4008\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 4.5825,\tval_loss: 4.3956\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 4.5567,\tval_loss: 4.3962\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 4.5724,\tval_loss: 4.4010\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 4.5904,\tval_loss: 4.4040\n",
      "9:\t[0s / 0s],\t\ttrain_loss: 4.5713,\tval_loss: 4.4020\n",
      "10:\t[0s / 0s],\t\ttrain_loss: 4.5739,\tval_loss: 4.3984\n",
      "11:\t[0s / 0s],\t\ttrain_loss: 4.5518,\tval_loss: 4.3959\n",
      "12:\t[0s / 0s],\t\ttrain_loss: 4.5459,\tval_loss: 4.3967\n",
      "13:\t[0s / 0s],\t\ttrain_loss: 4.5631,\tval_loss: 4.3964\n",
      "14:\t[0s / 1s],\t\ttrain_loss: 4.5520,\tval_loss: 4.3953\n",
      "15:\t[0s / 1s],\t\ttrain_loss: 4.5310,\tval_loss: 4.3949\n",
      "16:\t[0s / 1s],\t\ttrain_loss: 4.5671,\tval_loss: 4.3932\n",
      "17:\t[0s / 1s],\t\ttrain_loss: 4.5202,\tval_loss: 4.3856\n",
      "18:\t[0s / 1s],\t\ttrain_loss: 4.5173,\tval_loss: 4.3810\n",
      "19:\t[0s / 1s],\t\ttrain_loss: 4.5180,\tval_loss: 4.3816\n",
      "20:\t[0s / 1s],\t\ttrain_loss: 4.5076,\tval_loss: 4.3853\n",
      "21:\t[0s / 1s],\t\ttrain_loss: 4.5488,\tval_loss: 4.3878\n",
      "22:\t[0s / 1s],\t\ttrain_loss: 4.5226,\tval_loss: 4.3886\n",
      "23:\t[0s / 1s],\t\ttrain_loss: 4.4959,\tval_loss: 4.3837\n",
      "24:\t[0s / 1s],\t\ttrain_loss: 4.5087,\tval_loss: 4.3810\n",
      "25:\t[0s / 1s],\t\ttrain_loss: 4.4990,\tval_loss: 4.3801\n",
      "26:\t[0s / 1s],\t\ttrain_loss: 4.4997,\tval_loss: 4.3799\n",
      "27:\t[0s / 1s],\t\ttrain_loss: 4.5171,\tval_loss: 4.3785\n",
      "28:\t[0s / 1s],\t\ttrain_loss: 4.5130,\tval_loss: 4.3771\n",
      "29:\t[0s / 1s],\t\ttrain_loss: 4.5090,\tval_loss: 4.3797\n",
      "30:\t[0s / 1s],\t\ttrain_loss: 4.4854,\tval_loss: 4.3796\n",
      "31:\t[0s / 1s],\t\ttrain_loss: 4.4968,\tval_loss: 4.3807\n",
      "32:\t[0s / 1s],\t\ttrain_loss: 4.5005,\tval_loss: 4.3818\n",
      "33:\t[0s / 1s],\t\ttrain_loss: 4.4744,\tval_loss: 4.3858\n",
      "34:\t[0s / 1s],\t\ttrain_loss: 4.5099,\tval_loss: 4.3844\n",
      "35:\t[0s / 1s],\t\ttrain_loss: 4.4724,\tval_loss: 4.3852\n",
      "36:\t[0s / 1s],\t\ttrain_loss: 4.5120,\tval_loss: 4.3838\n",
      "37:\t[0s / 1s],\t\ttrain_loss: 4.4753,\tval_loss: 4.3812\n",
      "38:\t[0s / 1s],\t\ttrain_loss: 4.4896,\tval_loss: 4.3814\n",
      "CPU times: user 1.82 s, sys: 153 ms, total: 1.98 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log = model.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_hazards = model.compute_baseline_hazards()\n",
    "non_zero_idx = baseline_hazards[baseline_hazards>0].index[1] # 计算第一个非零元素的索引\n",
    "bh = baseline_hazards.loc[non_zero_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def compute_nonconformal_score_single(model,Z_tr,x,t,x_mapper,bh,non_zero_idx):\n",
    "    R = Z_tr[Z_tr['duration']>=t] # 找到at risk的人的covariates\n",
    "    if len(R) == 0: # 如果没找到at risk的人就跳过\n",
    "        return None\n",
    "    x_R = x_mapper.transform(R).astype('float32')\n",
    "    ch_r = model.predict_cumulative_hazards(x_R)\n",
    "    exp_g_r = ch_r.loc[non_zero_idx]/bh\n",
    "    return exp_g_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 计算nonconformal score的函数，给定一个预测hazard的模型，training set\n",
    "# 和calibration set以及base hazard，输出结果\n",
    "def compute_nonconformal_score(model,x_mapper,Z_tr,Z_ca,bh,non_zero_idx):\n",
    "    '''\n",
    "    model: 预测模型\n",
    "    Z_tr: traning set\n",
    "    Z_ca: calibration set\n",
    "    return: calibration set的 nonconformal score\n",
    "    '''\n",
    "    Z_ca_1 = Z_ca[Z_ca['event']==1] # calibration set中发病的样本\n",
    "    x_ca = x_mapper.transform(Z_ca_1).astype('float32')\n",
    "    durations_test_1, events_test_1 = get_target(Z_ca_1)\n",
    "    cumulative_hazards = model.predict_cumulative_hazards(x_ca)\n",
    "    exp_g = cumulative_hazards.loc[non_zero_idx].div(bh)\n",
    "    V = list()\n",
    "    for i in range(len(x_ca)): # nonconformal score\n",
    "        exp_g_r = compute_nonconformal_score_single(model,Z_tr,x_ca[i],durations_test_1[i],x_mapper,bh,non_zero_idx)\n",
    "        if exp_g_r is None:\n",
    "            V.append(np.inf)\n",
    "        else:\n",
    "            V.append(np.log(exp_g[i])-np.log(np.sum(exp_g_r)))\n",
    "    return np.array(V+[np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_ca_1 = Z_ca.sample(frac=0.99)\n",
    "Z_ca_2 = Z_ca.drop(Z_ca_1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算calibration set中Delta = 1的每个数据的权重\n",
    "W,clf = compute_weight('XGBoost',Z_tr,Z_ca_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_hazards = model.compute_baseline_hazards()\n",
    "non_zero_idx = baseline_hazards[baseline_hazards>0].index[1] # 计算第一个非零元素的索引\n",
    "bh = baseline_hazards.loc[non_zero_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = compute_nonconformal_score(model,x_mapper,Z_tr,Z_ca_1,bh,non_zero_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355.20001220703125"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_h = np.max(df_train['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.3000087738037\n",
      "260.8500089645386\n",
      "244.20000839233398\n",
      "263.625009059906\n"
     ]
    }
   ],
   "source": [
    "x_ca_2 = x_mapper.transform(Z_ca_2).astype('float32')\n",
    "for i in range(len(x_ca_2)):\n",
    "    x = np.array([x_ca_2[i]])\n",
    "    print(weighted_conformal_prediction(V,W,x,t_h,Z_tr,model,clf,0.95,bh,non_zero_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "X_idx = Z_ca[Z_ca['event']==1].to_numpy() # 找到Delta_i = 1的数据，转化成numpy数据\n",
    "Z_ca_1 = Z_ca[Z_ca['event']==1] # 找到Delta_i = 1的数据\n",
    "Z_ca_test = Z_ca_1.sample(frac=0.01) # 将calibration set中划出一部分用来test\n",
    "Z_ca_1 = Z_ca_1.drop(Z_ca_test.index)\n",
    "x_test_1 = x_mapper.transform(Z_ca_1).astype('float32')\n",
    "durations_test_1, events_test_1 = get_target(Z_ca_1)\n",
    "cumulative_hazards = model.predict_cumulative_hazards(x_test_1)\n",
    "exp_g = cumulative_hazards.loc[non_zero_idx].div(bh)\n",
    "# 计算nonconformal score\n",
    "V = list()\n",
    "ch = model.predict_cumulative_hazards(x_test_1) \n",
    "exp_g = ch.iloc[2,:]/bh\n",
    "p_hat, p_inf= list(),list()\n",
    "for i in range(len(x_test_1)):\n",
    "    t = durations_test_1[i]\n",
    "    R = Z_tr[Z_tr['event']==0][Z_tr['duration']>=t] # 找到at risk的人的covariates\n",
    "    if len(R) == 0: # 如果没找到at risk的人就跳过\n",
    "        continue\n",
    "    x_R = x_mapper.fit_transform(R).astype('float32')\n",
    "    ch_r = model.predict_cumulative_hazards(x_R)\n",
    "    exp_g_r = ch_r.loc[non_zero_idx]/bh\n",
    "    V.append(np.log(exp_g[i])-np.log(np.sum(exp_g_r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.91468555,  1.1301656 , -0.47822767, -0.789998  ,  0.7613344 ,\n",
       "         1.        ,  1.        ,  0.        ,  1.        ],\n",
       "       [-0.32096985,  0.7625667 ,  0.01102955, -0.5552923 , -0.8143126 ,\n",
       "         1.        ,  0.        ,  1.        ,  1.        ],\n",
       "       [ 2.2719808 , -1.0495    , -0.80151224,  1.5298384 ,  0.299441  ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [-0.5856291 ,  1.038398  , -0.6645023 , -0.30214155,  0.46566126,\n",
       "         0.        ,  1.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ca_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_ca_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0e293913f9db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ca_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test point %d: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweighted_conformal_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_ca_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_ca_test' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_ca_test)):\n",
    "    print('Test point %d: %f' % (i,weighted_conformal_prediction(V,W,x_ca_test[i][np.newaxis,:],clf,0.95)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_ca_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-bf1c77addeca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_ca_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_ca_test' is not defined"
     ]
    }
   ],
   "source": [
    "x_ca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 343.847,
   "position": {
    "height": "40px",
    "left": "146.24px",
    "right": "20px",
    "top": "17px",
    "width": "527px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
