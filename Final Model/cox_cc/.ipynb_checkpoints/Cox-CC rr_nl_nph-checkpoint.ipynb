{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla CoxCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pycox\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "from pycox.datasets import metabric\n",
    "from pycox.evaluation import EvalSurv\n",
    "from pycox.models import CoxCC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import joblib\n",
    "from pycox.simulations import SimStudyNonLinearNonPH\n",
    "from generate_data import load_data\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from weighted_conformal_prediction_coxcc import WeightedConformalPrediction\n",
    "from datetime import datetime\n",
    "from pycox.datasets import metabric,support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\t0.565\t232.000\t898.000\n",
      "[1]\t0.574\t237.000\t911.000\n",
      "[2]\t0.567\t231.000\t903.000\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.6,0.7,0.8,0.9]\n",
    "\n",
    "method = 'vanilla_cox_ph'\n",
    "data = 'rr_n_nph'\n",
    "\n",
    "df = load_data('rr_nl_nph.pkl')\n",
    "epochs = 10\n",
    "train_frac = 0.6\n",
    "test_frac = 0.2\n",
    "val_frac = 0.2\n",
    "for alpha in alphas:\n",
    "    coverage = []\n",
    "    coverage_censor = []\n",
    "    coverage_non_censor = []\n",
    "    for epoch in range(epochs):\n",
    "          rng = np.random.RandomState(epoch)\n",
    "          shuffle_idx = rng.permutation(range(len(df)))\n",
    "          train_idx = shuffle_idx[:int(train_frac*len(df))]\n",
    "          val_idx = shuffle_idx[int(train_frac*len(df)):int((train_frac+val_frac)*len(df))]\n",
    "          test_idx = shuffle_idx[int((train_frac+val_frac)*len(df)):]\n",
    "\n",
    "          df_train = df.iloc[train_idx,:]\n",
    "          df_val = df.iloc[val_idx,:]\n",
    "          df_test = df.iloc[test_idx,:]\n",
    "\n",
    "          cols_standardize = ['x0', 'x1', 'x2']\n",
    "\n",
    "          standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "          polyfeature = [([col], PolynomialFeatures()) for col in cols_standardize]\n",
    "          x_mapper = DataFrameMapper(standardize+polyfeature)\n",
    "\n",
    "          x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "          x_val = x_mapper.transform(df_val).astype('float32')\n",
    "          x_test = x_mapper.transform(df_test).astype('float32')\n",
    "\n",
    "          get_target = lambda df:(df['duration'].values,df['event'].values)\n",
    "          y_train = get_target(df_train)\n",
    "          y_val = get_target(df_val)\n",
    "          duration_test, event_test = get_target(df_test)\n",
    "\n",
    "          val = tt.tuplefy(x_val,y_val)\n",
    "\n",
    "          in_features = x_train.shape[1]\n",
    "          num_nodes = [32,32]\n",
    "          out_features = 1\n",
    "          batch_norm = True\n",
    "          dropout = 0.1\n",
    "          output_bias = False\n",
    "\n",
    "          net = tt.practical.MLPVanilla(in_features=in_features, num_nodes=num_nodes, out_features = out_features, batch_norm = batch_norm, dropout = dropout, output_bias = output_bias)\n",
    "\n",
    "          model = CoxCC(net,torch.optim.Adam)\n",
    "\n",
    "          batch_size = 256\n",
    "          n_epochs = 512\n",
    "          verbose = False\n",
    "          callbacks = [tt.callbacks.EarlyStopping()]\n",
    "          model.fit(x_train,y_train,batch_size,n_epochs,callbacks,verbose,val_data=val.repeat(10).cat())\n",
    "          _ = model.compute_baseline_hazards()\n",
    "\n",
    "          surv = model.predict_surv_df(x_test)\n",
    "          surv_ = (surv<=1-alpha).to_numpy(dtype='int8')\n",
    "          index = np.array(surv.index)\n",
    "          multiply_surv = np.transpose(surv_)*index\n",
    "          multiply_surv_ = np.where(multiply_surv==0,np.max(index),multiply_surv)\n",
    "\n",
    "          t_predict = multiply_surv_.min(axis = 1)\n",
    "          diff_predict_true = np.subtract(t_predict,np.array(df_test['duration_true']))\n",
    "\n",
    "          cover = sum(diff_predict_true>=0)/len(t_predict)\n",
    "          censor = 0\n",
    "          non_censor = 0\n",
    "          for i in range(len(df_test)):\n",
    "                if (diff_predict_true[i] >= 0):\n",
    "                      if (event_test[i]==0):\n",
    "                            censor += 1\n",
    "                      else:\n",
    "                            non_censor += 1\n",
    "\n",
    "          coverage.append(cover)\n",
    "          n_censor = len(df_test) - sum(df_test['event'])\n",
    "          if n_censor == 0:\n",
    "                coverage_censor.append(alpha)\n",
    "                coverage_non_censor.append(cover)\n",
    "          elif n_censor == len(df_test):\n",
    "                coverage_non_censor.append(alpha)\n",
    "                coverage_censor.append(cover)\n",
    "          else:\n",
    "                coverage_censor.append(censor/n_censor)\n",
    "                coverage_non_censor.append(non_censor/(len(df_test)-n_censor))\n",
    "\n",
    "          print('[%d]\\t%.3f\\t%.3f\\t%.3f'%(epoch,cover,censor,non_censor))\n",
    "\n",
    "    print('Total Coverage Statistics:\\t [Mean]%.3f\\t[Std.]%.3f\\t[Max]%.3f\\t[Min]%.3f'%(np.mean(coverage),np.std(coverage),np.max(coverage),np.min(coverage)))\n",
    "\n",
    "    np.savetxt('./output/vanilla_coxcc_coverage_'+data+'_'+str(alpha)+'_'+str(epochs)+'.txt',np.array(coverage))\n",
    "    np.savetxt('./output/vanilla_coxcc_censor_coverage_'+data+'_'+str(alpha)+'_'+str(epochs)+'.txt',np.array(coverage_censor))\n",
    "    np.savetxt('./output/vanilla_coxcc_non_censor_coverage_'+data+'_'+str(alpha)+'_'+str(epochs)+'.txt',np.array(coverage_non_censor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
